from fastapi import APIRouter, Request
from pydantic import BaseModel
from fastapi.responses import StreamingResponse
from app.agent.factory import get_graph_runnable
from app.services.chat_graph import save_chat_history
from app.core.database import AsyncSessionLocal  # ğŸ”¥ ä» database.py å¯¼å…¥ Session å·¥å‚
from langchain_core.messages import HumanMessage
import json
import logging

router = APIRouter()
logger = logging.getLogger(__name__)


class ChatRequest(BaseModel):
    session_id: str
    message: str


logger = logging.getLogger(__name__)
router = APIRouter()


@router.post("/rest/dark/v1/agent/chat")
async def chat_endpoint(request: Request, body: ChatRequest):
    # 1. æ‹¿åˆ°è¿æ¥æ± 
    lg_pool = request.app.state.lg_pool

    async def event_generator():
        # ğŸ”¥ 2. æ‰‹åŠ¨ç”³è¯·è¿æ¥ (Context Manager)
        # è¿™æ ·è¿æ¥çš„ç”Ÿå‘½å‘¨æœŸå°±å®Œå…¨è¦†ç›–äº†æ•´ä¸ªæµå¼å“åº”è¿‡ç¨‹ (Start -> End)
        async with lg_pool.connection() as conn:
            try:
                # ğŸ”¥ğŸ”¥ 3. æ ¸å¼¹çº§ä¿®å¤ï¼šå†æ¬¡å¼ºåˆ¶ç¦ç”¨ Prepared Statements
                # è™½ç„¶ main.py é…äº†ï¼Œä½†ä¸ºäº† 100% ç¡®ä¿è¿™ä¸ªä¼šè¯ä¸æŠ¥é”™ï¼Œè¿™é‡Œå†è®¾ä¸€æ¬¡
                conn.prepare_threshold = None

                # 4. æŠŠè¿™ä¸ªâ€œå¹²å‡€â€çš„è¿æ¥ä¼ ç»™ Graph
                graph = await get_graph_runnable(conn)

                input_message = HumanMessage(content=body.message)
                config = {"configurable": {"thread_id": body.session_id}}
                final_response = ""

                # 5. è¿è¡Œ Graph (ä½¿ç”¨å½“å‰çš„ conn)
                async for event in graph.astream_events(
                    {"messages": [input_message]}, config, version="v1"
                ):
                    kind = event["event"]
                    # ... å¤„ç†æµé€»è¾‘ ...
                    if kind == "on_chain_end" and event["name"] == "agent":
                        output = event["data"]["output"]
                        # å…¼å®¹æ€§å¤„ç†ï¼Œé˜²æ­¢ output ä¸º None
                        if output and "messages" in output and output["messages"]:
                            final_response = output["messages"][-1].content
                            yield f"data: {json.dumps({'content': final_response})}\n\n"

                    # è¿˜å¯ä»¥åŠ ä¸ªå¿ƒè·³ï¼Œé˜²æ­¢ä¸­é—´é™é»˜å¤ªä¹…è¢«é˜²ç«å¢™åˆ‡æ–­
                    # yield ": keep-alive\n\n"

                yield "data: [DONE]\n\n"

            except Exception as e:
                logger.error(f"Stream error: {e}", exc_info=True)
                yield f"data: {json.dumps({'error': str(e)})}\n\n"

            # ç¦»å¼€ async with æ—¶ï¼Œè¿æ¥ä¼šè‡ªåŠ¨ rollback (å¦‚æœå‡ºé”™) å¹¶å½’è¿˜ç»™ pool

        # --- 6. å†å²è®°å½•ä¿å­˜ (è¿æ¥å½’è¿˜åå•ç‹¬è¿›è¡Œ) ---
        # æ­¤æ—¶ conn å·²ç»è¿˜å›å»äº†ï¼Œæˆ‘ä»¬ç”¨ SQLAlchemy çš„æ–°è¿æ¥å­˜å†å²
        if final_response:
            async with AsyncSessionLocal() as session:
                try:
                    await save_chat_history(
                        session, body.session_id, body.message, final_response
                    )
                except Exception as e:
                    logger.error(f"History save failed: {e}")

    return StreamingResponse(event_generator(), media_type="text/event-stream")
